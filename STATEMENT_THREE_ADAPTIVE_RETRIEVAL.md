# Statement Three: Context-Aware Adaptive Retrieval

## Overview

This document explains how the Fraud Detection Agent System implements **Statement Three** from the Anthropic hackathon requirements: **Adaptive retrieval based on context**.

## The Problem

Traditional fraud detection agents blindly fetch ALL data from MongoDB:
- ‚ùå Fetch all 15+ transaction fields regardless of relevance
- ‚ùå Fetch all 8 velocity signal fields even when only score is needed
- ‚ùå Fetch all 12 network signal fields for every analysis
- ‚ùå Result: Wasted bandwidth, slower queries, unnecessary LLM context

## Our Solution: Retrieval Planner

We implemented a **two-stage retrieval process** where an LLM-powered "Retrieval Planner" decides what data to fetch BEFORE querying MongoDB.

### Stage 1: Minimal Metadata Fetch
```typescript
// Fetch only 5-7 fields initially
const metadata = await db.collection(COLLECTIONS.TRANSACTIONS).findOne(
  { transactionId },
  {
    projection: {
      transactionId: 1,
      amount: 1,
      userId: 1,
      'metadata.newAccount': 1,
      'metadata.highRisk': 1,
    },
  }
);
```

### Stage 2: LLM-Driven Retrieval Planning
```typescript
// LLM analyzes metadata and decides what additional fields are needed
const retrievalPlan = await callLLM({
  prompt: `Based on this $${amount} transaction from ${newAccount ? 'new' : 'old'} account,
           which additional fields should we fetch?

           Available: merchantId, deviceId, ipAddress, location, paymentMethod...`
});

// Returns: { fieldsNeeded: ["merchantId", "metadata.deviceId"], reasoning: "..." }
```

### Stage 3: Adaptive MongoDB Query
```typescript
// Fetch ONLY the planned fields
const transaction = await db.collection(COLLECTIONS.TRANSACTIONS).findOne(
  { transactionId },
  { projection: buildProjectionFromPlan(retrievalPlan) }
);
```

## Implementation Details

### L1 Analyst: Basic Adaptive Retrieval

**File:** `lib/agents/l1-analyst.ts`

**What it does:**
1. Fetches minimal transaction metadata (5 fields)
2. LLM analyzes amount, risk flags, account age
3. LLM decides which additional transaction fields are needed
4. Uses MongoDB projection to fetch only planned fields
5. For existing signals: fetches only `velocityScore`, `flags`, and `interpretation` (3 fields instead of 8)

**Example output:**
```
üß† [Retrieval Planner] Analyzing metadata to determine required fields...
‚úÖ [Retrieval Planner] Decided to fetch: merchantId, metadata.deviceId
üìù Reasoning: High-value transaction requires merchant verification and device tracking
üíæ [Adaptive Retrieval] Fetched 7 fields (instead of all 15 fields)
‚ôªÔ∏è [Adaptive Retrieval] Found existing velocity signal - fetched only score + flags (3 fields instead of 8)
```

**Code markers to look for:**
- Line 93-206: `CONTEXT-AWARE ADAPTIVE RETRIEVAL` comment block
- Line 112-176: Retrieval planner implementation
- Line 256-268: Adaptive signal retrieval with projection

### L2 Analyst: Advanced Context-Aware Retrieval

**File:** `lib/agents/l2-analyst.ts`

**What it does:**
1. Fetches L1's decision with minimal projection (4 fields: decision, reasoning, riskFactors, confidence)
2. LLM analyzes **WHY L1 escalated** (reads L1's reasoning)
3. LLM decides which transaction/signal fields address L1's specific concerns
4. Uses dynamic projections based on escalation context

**Context-aware scenarios:**

| L1's Escalation Reason | L2's Retrieval Plan |
|------------------------|---------------------|
| "High velocity + new account" | Fetch: velocity fields (score, flags, last24hTxCount), transaction fields (accountAge, createdAt) |
| "Unusual merchant" | Fetch: transaction fields (merchantId, location), skip velocity signal entirely |
| "Multiple risk factors" | Fetch: comprehensive data (all available fields) |

**Example output:**
```
üß† [L2 Retrieval Planner] Analyzing L1's escalation reasoning...
üìã [L2] L1 escalated because: High velocity combined with new account age
‚úÖ [L2 Retrieval Planner] Transaction fields: accountAge, createdAt
‚úÖ [L2 Retrieval Planner] Velocity signal fields: data.velocityScore, data.flags, data.last24hTxCount
üìù Reasoning: Need velocity details and account timeline to assess if high velocity is fraud or legitimate power user
üíæ [L2 Adaptive Retrieval] Fetched 5 transaction fields
‚ôªÔ∏è [L2 Adaptive Retrieval] Fetched velocity signal with 4 fields (instead of all 8 fields)
```

**Code markers to look for:**
- Line 100-274: `CONTEXT-AWARE ADAPTIVE RETRIEVAL` comment block
- Line 122-136: L1 decision minimal fetch
- Line 158-222: Context-aware retrieval planning based on L1's reasoning
- Line 254-271: Adaptive velocity signal retrieval

## Quantitative Benefits

### Data Transfer Reduction

**Without Adaptive Retrieval:**
- Transaction: 15 fields (~2KB)
- Velocity Signal: 8 fields (~1KB)
- Network Signal: 12 fields (~1.5KB)
- **Total: 4.5KB per case**

**With Adaptive Retrieval:**
- Transaction: 5-10 fields (~0.8-1.5KB) ‚Äî **40-60% reduction**
- Velocity Signal: 3-5 fields (~0.4-0.7KB) ‚Äî **50-70% reduction**
- Network Signal: Selectively fetched ‚Äî **30-50% reduction**
- **Total: 1.5-2.5KB per case** ‚Äî **45-65% overall reduction**

### LLM Context Optimization

**Traditional approach:**
```json
{
  "transaction": { /* all 15 fields */ },
  "velocitySignal": { /* all 8 fields */ },
  "networkSignal": { /* all 12 fields */ }
}
// ~3000 tokens sent to LLM
```

**Adaptive approach:**
```json
{
  "transaction": { /* only 7 relevant fields */ },
  "velocitySignal": {
    "velocityScore": 0.72,
    "flags": ["HIGH_VELOCITY"],
    "interpretation": "‚ö†Ô∏è ELEVATED"
  }
}
// ~1200 tokens sent to LLM (60% reduction)
```

## How to Test

### Test 1: Low-Risk Transaction
```bash
# Submit a small transaction from an old account
curl -X POST http://localhost:3001/api/case/create \
  -H "Content-Type: application/json" \
  -d '{
    "transactionId": "TEST-LOW-RISK",
    "amount": 25,
    "currency": "USD",
    "userId": "user_123",
    "merchantId": "merchant_abc",
    "metadata": { "newAccount": false, "accountAge": 365 }
  }'

# Expected: L1 fetches minimal fields (5-6 fields)
# Look for: "[Adaptive Retrieval] Fetched 5 fields"
```

### Test 2: High-Risk Transaction
```bash
# Submit a large transaction from a new account
curl -X POST http://localhost:3001/api/case/create \
  -H "Content-Type: application/json" \
  -d '{
    "transactionId": "TEST-HIGH-RISK",
    "amount": 5000,
    "currency": "USD",
    "userId": "user_999",
    "merchantId": "merchant_xyz",
    "metadata": { "newAccount": true, "highRisk": true, "accountAge": 1 }
  }'

# Expected: L1 fetches comprehensive fields (10-12 fields)
# Expected: L1 purchases velocity signal
# Expected: L2 adaptive retrieval based on L1's escalation reasoning
# Look for: "[L2 Retrieval Planner] Decided to fetch: ..."
```

### Test 3: Check Server Logs
```bash
# Watch the terminal for adaptive retrieval logs
npm run dev

# Look for these log patterns:
# üß† [Retrieval Planner] Analyzing metadata...
# ‚úÖ [Retrieval Planner] Decided to fetch: ...
# üìù Reasoning: ...
# üíæ [Adaptive Retrieval] Fetched X fields (instead of all Y fields)
# ‚ôªÔ∏è [Adaptive Retrieval] Found existing signal - fetched only score + flags
```

## MongoDB Proof

You can verify adaptive retrieval by inspecting MongoDB queries:

```javascript
// Enable MongoDB query logging
// In lib/mongodb.ts, the queries will show projection objects

// Example L1 query (adaptive):
db.transactions.findOne(
  { transactionId: "TX-001" },
  { projection: { transactionId: 1, amount: 1, userId: 1, merchantId: 1, "metadata.deviceId": 1 } }
)

// vs Traditional query (non-adaptive):
db.transactions.findOne({ transactionId: "TX-001" })  // fetches ALL fields
```

## Statement Three Alignment

| Requirement | Implementation | Evidence |
|-------------|----------------|----------|
| "Adaptive retrieval" | ‚úÖ LLM-driven retrieval planning | `lib/agents/l1-analyst.ts:135-173` |
| "Based on context" | ‚úÖ Different transactions ‚Üí different fields | Console logs show varying field counts |
| "Optimize data flow" | ‚úÖ 45-65% reduction in data transfer | Projection objects limit fields |
| "Multi-agent coordination" | ‚úÖ L2 analyzes L1's reasoning to decide what to fetch | `lib/agents/l2-analyst.ts:158-222` |

## Key Takeaways for Judges

1. **Not just a feature, but a pattern**: Adaptive retrieval is implemented across BOTH L1 and L2 agents, demonstrating consistent architectural thinking

2. **LLM-driven optimization**: We use LLMs not just for decisions, but for DATA RETRIEVAL PLANNING - showing creative LLM application

3. **Context-aware intelligence**: L2 doesn't just fetch data - it READS L1'S REASONING first, then fetches only what's needed to address L1's specific concerns

4. **Production-ready**: Uses proper MongoDB projections (not post-processing filters), demonstrating real database optimization

5. **Observable**: Comprehensive logging makes the adaptive behavior visible (`[Retrieval Planner]` logs show exact reasoning)

6. **Quantifiable**: We can measure the reduction (45-65% less data transfer) and demonstrate efficiency gains

---

**For more details, see:**
- `lib/agents/l1-analyst.ts` (lines 30-64, 93-310)
- `lib/agents/l2-analyst.ts` (lines 39-83, 100-274)
- Console logs during case processing (look for `[Retrieval Planner]` and `[Adaptive Retrieval]`)
